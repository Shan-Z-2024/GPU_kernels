#include <cuda.h>
#include <cuda_runtime_api.h>
#include <cuda_runtime.h>
#include <cuda_fp8.h>
#include <time.h>

//for block level max_reduce during quantization 
#include <cub/block/block_radix_sort.cuh>
#include <cub/warp/warp_reduce.cuh>
#include <cub/block/block_load.cuh>
#include <cub/block/block_discontinuity.cuh>
#include <cub/block/block_store.cuh>
#include <cub/block/block_reduce.cuh>
#include <cub/cub.cuh>
#include <sys/time.h>
#include <float.h> //FLT_MAX

//cutlass fp8
#include <cutlass/float8.h>
#include <cutlass/numeric_types.h>

//local implementation
#include <load.cuh>

#define HLF_MAX 65504
#define TH 1024
#define NUM 4
#define NUM_BLOCK 4096
#define WARPSIZE 32

#define fp8_interpretation __NV_E4M3
#define E4M3_MAX 448.0f 

using fp8_e4m3 = cutlass::float_e4m3_t;

typedef enum DataType_t
{
        General8bit = 0,
        FP4 = 1,
  NF4 = 2,
} DataType_t;

#define CHECK_CUDA_ERROR(val) check((val), #val, __FILE__, __LINE__)
void check(cudaError_t err, const char* const func, const char* const file,
           const int line)
{
    if (err != cudaSuccess)
    {
        std::cerr << "CUDA Runtime Error at: " << file << ":" << line
                  << std::endl;
        std::cerr << cudaGetErrorString(err) << " " << func << std::endl;
        // We don't exit when we encounter CUDA errors in this example.
        // std::exit(EXIT_FAILURE);
    }
}

#define CHECK_LAST_CUDA_ERROR() checkLast(__FILE__, __LINE__)
void checkLast(const char* const file, const int line)
{
    cudaError_t const err{cudaGetLastError()};
    if (err != cudaSuccess)
    {
        std::cerr << "CUDA Runtime Error at: " << file << ":" << line
                  << std::endl;
        std::cerr << cudaGetErrorString(err) << std::endl;
        // We don't exit when we encounter CUDA errors in this example.
        // std::exit(EXIT_FAILURE);
    }
}

template <typename T>
void randomize_matrix(T *mat, int N) {
  // NOTICE: Use gettimeofday instead of srand((unsigned)time(NULL)); the time
  // precision is too low and the same random number is generated.
  struct timeval time {};
  gettimeofday(&time, nullptr);
  srand(time.tv_usec);
  for (int i = 0; i < N; i++) {
    float tmp = (float)(rand() % 65535) + 0.01 * (rand() % 100);
    tmp = (rand() % 2 == 0) ? tmp : (tmp * (-1.));
    mat[i] = (T)tmp;
  }
}

template <typename T>
void zero_matrix(T *mat, int N) {
  // initialize with zeros
  for (int i = 0; i < N; i++) {
    float tmp = 0.0; 
    mat[i] = (T)tmp;
  }
}


__device__ unsigned char dQuantizeFP4(float x)
{
  // FP4 with bias of 3
  // first bit is a sign
  // subnormals
  // 0b000 = 0
  // 0b001 = 0.0625
  // 0b110 = 2
  // 0b111 = 3
  // 0b100 = 4
  // 0b101 = 6
  // 0b010 = 8
  // 0b011 = 12


  // we do a binary search
  // the pivots are divided by 12 (the FP4 absmax)
  // since we assume input data is in [-1.0, 1.0]

  // !be careful here, its easy to make a mistake
  // that is difficult to notice if you add an extra
  // zero somewhere!

  int sign = x < 0 ? 0b1000 : 0b0000;
  x = fabsf(x);
  if(x > 0.29166667f)
    if( x > 0.583333f)
      if( x > 0.8333333f)
        return 0b0011+sign;
      else
        return 0b0010+sign;
    else
      if(x > 0.4166667f)
        return 0b101+sign;
      else
        return 0b100+sign;
 else
    if(x > 0.0859375f)
      if(x > 0.20833333f)
        return 0b0111+sign;
      else
        return 0b0110+sign;
    else
      if(x > 0.00260417f)
        return 0b0001+sign;
      else
        return 0b0000+sign;
}

__device__ unsigned char dQuantizeNF4(float x)
{

  // the values for this tree was generated by test_normal_map_tree
  // in the file tests/test_functional.py
  if(x > 0.03979014977812767f)
    if(x > 0.3893125355243683f) // 1
      if(x > 0.6427869200706482f) // 11
        if(x > 0.8614784181118011f) // 111
          return 0b1111;
        else
          return 0b1110;
      else
        if(x > 0.5016634166240692f) // 110
          return 0b1101;
        else
          return 0b1100;
    else
      if(x > 0.2035212516784668f) // 10
        if(x > 0.2920137718319893f) // 101
          return 0b1011;
        else
          return 0b1010;
      else
        if(x > 0.1202552504837513f) // 100
          return 0b1001;
        else
          return 0b1000;
  else
    if(x > -0.33967943489551544f) // 0
      if(x > -0.13791173323988914f) // 01
        if(x > -0.045525018125772476f) // 011
          return 0b0111;
        else
          return 0b0110;
      else
        if(x > -0.23460740596055984f) // 010
          return 0b0101;
        else
          return 0b0100;
    else
      if(x > -0.6106329262256622f) // 00
        if(x > -0.4599952697753906f) // 001
          return 0b0011;
        else
          return 0b0010;
      else
        if(x > -0.8480964004993439f) // 000
          return 0b0001;
        else
          return 0b0000;
}

//TODO, add fp8 quantization for e5m2 or e4m3 for quantization

__device__ half dhDequantizeNF4(unsigned char val)
{
  // the values for this tree was generated by test_normal_map_tree
  // in the file tests/test_functional.py
  if((val & 0b1000) == 8)
    if((val & 0b0100) == 4) // 1
      if((val & 0b0010) == 2) // 11
        if((val & 0b0001) == 1) // 111
          return 1.0f;
        else
          return 0.7229568362236023f;
      else
        if((val & 0b0001) == 1) // 110
          return 0.5626170039176941f;
        else
          return 0.44070982933044434f;
   else
      if((val & 0b0010) == 2) //10
        if((val & 0b0001) == 1) // 101
          return 0.33791524171829224f;
        else
          return 0.24611230194568634f;
      else
        if((val & 0b0001) == 1) // 100
          return 0.16093020141124725f;
        else
          return 0.07958029955625534f;

  else
    if((val & 0b0100) == 4) // 0
      if((val & 0b0010) == 2) //01
        if((val & 0b0001) == 1) // 011
          return 0.0f;
        else
          return -0.09105003625154495f;
      else
        if((val & 0b0001) == 1) // 010
          return -0.18477343022823334f;
        else
          return -0.28444138169288635f;
    else
      if((val & 0b0010) == 2) //00
        if((val & 0b0001) == 1) // 001
          return -0.39491748809814453f;
        else
          return -0.5250730514526367f;
      else
        if((val & 0b0001) == 1) // 000
          return -0.6961928009986877f;
        else
          return -1.0f;

}


//enum DATA_TYPE{"8_BIT", "FP4", "NFP4"};

template<typename T, const int BLOCK_SIZE_X, const int BLOCK_SIZE_Y, const int NUM_PER_TH, int DATA_TYPE, int BLOCK_SIZE_Q=128>
__launch_bounds__(4096)
__global__ void	quantize_block_wize(float* A, T* outputs, float *absmax, const int m, const int n){
		//BLOCKSIZE as 2D and ThreadIdx as 1D, BLOCK_SIZE_Q for quantization
		//Here is for 128x128 block_size reduce and quantization
		// here both BLOCK_SIZE_Y and BLOCK_SIZE_X is 128x128, NUM_PER_TH = 4
	        // this implementation, we set default row BLOCK_SIZE_Y=16, 16x128
		//const uint Row_Block = blockIdx.y;
		//const uint Col_Block = blockIdx.x;
	        //warpIdx
		const uint warpIdx = threadIdx.x / WARPSIZE;
		const int m_full = gridDim.x * BLOCK_SIZE_X;
		const int n_full = gridDim.y * BLOCK_SIZE_Y;
		int valid_items = 0, valid_items_x = 0, valid_items_y = 0;
		const int base_idx_x = (blockIdx.x * BLOCK_SIZE_X);
		const int base_idx_y = (blockIdx.y * BLOCK_SIZE_Y);
		bool STOCHASTIC = false;

		// every block total number of blocks
		constexpr uint NUM_THREADS = BLOCK_SIZE_X * BLOCK_SIZE_Y / NUM_PER_TH;
		//every block A location;
		//if (threadIdx.x == 0 and blockIdx.x==0) printf("current first element in A is %f \n", A[0]);
		const int block_offset = base_idx_y * n + base_idx_x;
		A += block_offset; //base_idx_y * n + base_idx_x;
		//if(threadIdx.x == 0 and blockIdx.x==0)printf("current offset base_idx_x is %d and base_idx_y is %d and total offset is %d  and val is %f \n", base_idx_x, base_idx_y, block_offset, A[0]);
		
		// allocate space for the current blocktile in SMEM
		__shared__ float As[BLOCK_SIZE_X * BLOCK_SIZE_Y];// BLOCK_SIZE_X is num of cols
		// for quantized store
		//__shared__ unsigned char Qs[BLOCK_SIZE_X * BLOCK_SIZE_Y];

		// calculating the indices that this thread will load into SMEM
		// we'll load 128bit / 32bit = 4 elements per thread at each step
		const uint innerRow = threadIdx.x / (BLOCK_SIZE_X/4);
		const uint innerCol = threadIdx.x % (BLOCK_SIZE_X/4);
		constexpr uint rowStride = BLOCK_SIZE_Y;

		//typedef cub::BlockLoad<T, BLOCK_SIZE_X/NUM_PER_TH, NUM_PER_TH, cub::BLOCK_LOAD_WARP_TRANSPOSE, BLOCK_SIZE_Y> LoadT;
		//typedef cub::BlockStore<unsigned char, BLOCK_SIZE_X/NUM_PER_TH, (DATA_TYPE > 0) ? NUM_PER_TH/2 : NUM_PER_TH, cub::BLOCK_STORE_WARP_TRANSPOSE, BLOCK_SIZE_Y> StoreChar;
		cub::BlockReduceAlgorithm const reduce_alg = cub::BLOCK_REDUCE_WARP_REDUCTIONS;
		typedef cub::BlockReduce<float, NUM_THREADS, reduce_alg> BlockReduce;
		//typedef cub::BlockLoad<float, BLOCK_SIZE_X/NUM_PER_TH, NUM_PER_TH, cub::BLOCK_LOAD_WARP_TRANSPOSE, BLOCK_SIZE_Y> LoadFloat;
		// __shared__ typename LoadT::TempStorage loadt;
		// __shared__ typename LoadFloat::TempStorage loadf; for stochatic quantization
		//__shared__ typename StoreChar::TempStorage storec;
		__shared__ typename BlockReduce::TempStorage reduce;
		//if (threadIdx.x == 0){
		//	printf("for store %d and reduce shared mem size %d \n", storec, reduce);
		//}
		//__shared__ float smem_code[256];
		__shared__ float smem_absmax_value[1];

		//thread local variable
		float vals[NUM_PER_TH]; //vals at register have the same data type as input A
		float rand_vals[NUM_PER_TH];
		//signed char qvals[(DATA_TYPE > 0) ? NUM_PER_TH/2 : NUM_PER_TH];
		fp8_e4m3 qvals[(DATA_TYPE > 0) ? NUM_PER_TH/2 : NUM_PER_TH];
		//if (DATA_TYPE > 0) fp8_e4m3 qvals[NUM_PER_TH];
		//else unsigned char qvals[NUM_PER_TH/2]
		float local_abs_max = -FLT_MAX;
		//float local_abs_max = 0.0f;
		int local_rand_idx = 0;

		//perform local block thread reduce and quantization
		//define new local __device__ quantization 
		//if(DATA_TYPE == General8bit)
		//	for(int i = threadIdx.x; i < 256; i+=blockDim.x)
		//		smem_code[i] = code[i];
	        int rand_offset = 0;	
		for (unsigned int i = base_idx_x; i < n; i += gridDim.x*BLOCK_SIZE_X)
			for (unsigned int j = base_idx_y; j < m; j += gridDim.y*BLOCK_SIZE_Y)
			  {
			    //for later 
			    valid_items_x = n - i > BLOCK_SIZE_X ? BLOCK_SIZE_X : n - i; //for boundary check along x dim
			    valid_items_y = m - j > BLOCK_SIZE_Y ? BLOCK_SIZE_Y : m - j; // for boundary check along y dim
			    //TODO double check the 2D valid_items
			    valid_items = valid_items_x * valid_items_y;
			    //local_abs_max = -FLT_MAX;

			    //__syncthreads();
			    // loadGToS only supports m,n divisible BLOCK_SIZE_Y, BLOCK_SIZE_X 
			    loadGToS<BLOCK_SIZE_Y, BLOCK_SIZE_X, float>(A, As, m, n, rowStride, innerRow, innerCol);
			    // load from shared memory to register
			    // offsets in shared memory
			    __syncthreads();
		            //if(threadIdx.x == 0 and blockIdx.x==0)printf("current offset base_idx_x is %d and base_idx_y is %d and total offset is %d  and val is %f \n", base_idx_x, base_idx_y, block_offset, As[0]);
			    //const int offsets = threadIdx.x;
			    //loadSToR<NUM_PER_TH, NUM_THREADS, float>(As, vals, offsets);// offsets of every val in As
			    //LoadT(loadt).Load(&(A[i * n + j]), vals, valid_items, (T)0.0f);

			    // 1. compute local max
			    // 2. broadcast local max
			    // 3. normalize inputs and quantize
                            #pragma unroll NUM_PER_TH
			    for (uint idx =0; idx < NUM_PER_TH; idx++){
				    vals[idx] = As[threadIdx.x + idx * NUM_THREADS];}

                            #pragma unroll NUM_PER_TH
			    for(int k = 0; k < NUM_PER_TH; k++)
			       local_abs_max = fmaxf(local_abs_max, fabsf((float)vals[k]));

			    __syncthreads();
			    float block_abs_max = BlockReduce(reduce).Reduce(local_abs_max, cub::Max(), valid_items);

			    if(threadIdx.x == 0){
			      smem_absmax_value[0] = block_abs_max;
			    }
			    //if(threadIdx.x==0 and blockIdx.x==0 and blockIdx.y==0)printf("current thread val for first element is: %f and first block As %f MAX IS %f offsets is %d \n", vals[0], As[0], block_abs_max, block_offset);
			    //if(threadIdx.x==0 and blockIdx.x==0 and blockIdx.y==1)printf("current thread val for first element is: %f and second block As %f MAX IS %f offsets is %d \n", vals[0], As[0], block_abs_max, block_offset);

			    __syncthreads();

			    if(threadIdx.x == 0){
			      //uint offsets_to_w = i/BLOCK_SIZE_X + j/BLOCK_SIZE_Y * (n/BLOCK_SIZE_X);
			      //if (blockIdx.x==0)printf("current offsets and i is %d j is %d and max is %f \n", i, j, block_abs_max);
			      absmax[i/BLOCK_SIZE_X + j/BLOCK_SIZE_Y * (n/BLOCK_SIZE_X)] = block_abs_max;}
			    else
			      block_abs_max = smem_absmax_value[0];

			    __syncthreads();

			    local_abs_max = E4M3_MAX/block_abs_max;
			    //if(STOCHASTIC)
			    //{
			    //  local_rand_idx = ((blockIdx.x*blockDim.x + blockIdx.y*blockDim.y) + (threadIdx.x*NUM) + rand_offset) % (1024-4);
			    //  LoadFloat(loadf).Load(&rand[local_rand_idx], rand_vals, BLOCK_SIZE, 0);
			    // }

			    unsigned char packed_4bit = 0;
			    switch(DATA_TYPE)
			    {
				case General8bit:
				    //local_abs_max = local_abs_max * E4M3_MAX;
				    //if(threadIdx.x==0 and blockIdx.x==0 and blockIdx.y ==0 )printf("local_max is is: %f and fp8_max is %f, and block_offset is %d \n", local_abs_max, E4M3_MAX, block_offset);
				    //if(threadIdx.x==0 and blockIdx.x==0 and blockIdx.y ==1 )printf("local_max is is: %f and fp8_max is %f, and block_offset is %d \n", local_abs_max, E4M3_MAX, block_offset);
				    #pragma unroll NUM_PER_TH
				    for(int k = 0; k < NUM_PER_TH; k++)
				    {
					//if(!STOCHASTIC)
					qvals[k] = (fp8_e4m3)(vals[k] * local_abs_max);
					//qvals[k] = __nv_cvt_float_to_fp8((float)vals[k] * local_abs_max, __NV_SATFINITE, __NV_E4M3);
                                //      //const __nv_fp8_interpretation_t fp8_interpretation);
				//      //qvals[j] = dQuantize<0>(smem_code, 0.0f, ((float)vals[j])*local_abs_max);
				//	else
				//	 qvals[j] = dQuantize<1>(smem_code, rand_vals[j], ((float)vals[j])*local_abs_max);
				    }
				    //if (threadIdx.x == 0 and blockIdx.x==0) printf("current block_idx_y: %d and vals brefore %f and after quantization %f \n", blockIdx.y, vals[0], qvals[0]);
				    break;
				case FP4:
				    #pragma unroll NUM_PER_TH
				    for(int k = 0; k < NUM_PER_TH/2; k++)
				    {
				      packed_4bit |= dQuantizeFP4(((float)vals[2*k])*local_abs_max) << 4;
				      packed_4bit |= dQuantizeFP4(((float)vals[2*k+1])*local_abs_max);
				      //qvals[j] = packed_4bit;
				    }
				    break;
				case NF4:
				    #pragma unroll NUM_PER_TH
				    for(int k = 0; k < NUM_PER_TH/2; k++)
				    {
				      packed_4bit |= dQuantizeNF4(((float)vals[2*k])*local_abs_max) << 4;
				      packed_4bit |= dQuantizeNF4(((float)vals[2*k+1])*local_abs_max);
				      //qvals[j] = packed_4bit;
				    }
				    break;
			    }

		    __syncthreads();
		    //TODO SHAN, store with i and j for offsets
		    //StoreChar(storec).Store(&(outputs[(DATA_TYPE > 0) ? i/2 : i]), qvals, (DATA_TYPE > 0) ? (valid_items+1)/2 : valid_items);
		    if (DATA_TYPE > 0){
			    //direct write to outputs, for 8bit, with every thread NUM_PER_THREAD
			    uint const rowOffset = j + innerRow;
			    uint const colOffset = i + innerCol;
			    #pragma unroll NUM_PER_TH
                            for(int k = 0; k < NUM_PER_TH; k++){
				    outputs[rowOffset * n + colOffset + k * BLOCK_SIZE_X] = qvals[k];
			    }
		    }
		    else{
			    //direct write to outputs, for 4 bits, with every thread NUM_PER_THREAD/2
			    uint const rowOffset = j + innerRow;
                            uint const colOffset = i + innerCol;
                            #pragma unroll NUM_PER_TH
                            for(int k = 0; k < NUM_PER_TH/2; k++){
                                    outputs[rowOffset * n + colOffset + k * BLOCK_SIZE_X] = qvals[k];
                            }
		    }
			  };
}

void CudaDeviceInfo() {
  int deviceId;

  cudaGetDevice(&deviceId);

  cudaDeviceProp props{};
  cudaGetDeviceProperties(&props, deviceId);

  printf("Device ID: %d\n\
    Name: %s\n\
    Compute Capability: %d.%d\n\
    memoryBusWidth: %d\n\
    maxThreadsPerBlock: %d\n\
    maxThreadsPerMultiProcessor: %d\n\
    maxRegsPerBlock: %d\n\
    maxRegsPerMultiProcessor: %d\n\
    totalGlobalMem: %zuMB\n\
    sharedMemPerBlock: %zuKB\n\
    sharedMemPerMultiprocessor: %zuKB\n\
    totalConstMem: %zuKB\n\
    multiProcessorCount: %d\n\
    Warp Size: %d\n",
         deviceId, props.name, props.major, props.minor, props.memoryBusWidth,
         props.maxThreadsPerBlock, props.maxThreadsPerMultiProcessor,
         props.regsPerBlock, props.regsPerMultiprocessor,
         props.totalGlobalMem / 1024 / 1024, props.sharedMemPerBlock / 1024,
         props.sharedMemPerMultiprocessor / 1024, props.totalConstMem / 1024,
         props.multiProcessorCount, props.warpSize);
};
/***
template <const int BM, const int BN, const int BK, const int WM, const int WN,
          const int WNITER, const int TM, const int TN, const int NUM_THREADS>
__global__ void __launch_bounds__(NUM_THREADS)
    QuantizeBlockwise(const int M, const int N, const int K,
                         const float alpha, float *A, float *B, float beta,
                         float *C) {
  const uint cRow = blockIdx.y;
  const uint cCol = blockIdx.x;

  // Placement of the warp in the threadblock tile
  const uint warpIdx = threadIdx.x / WARPSIZE; // the warp this thread is in
  const uint warpCol = warpIdx % (BN / WN);
  const uint warpRow = warpIdx / (BN / WN);
    }***/

int main(){
	CudaDeviceInfo();
	std::vector<int> SIZE = {4096, 8192, 512, 4096, 8192};
	long m, n, k, max_size; // max size for the biggest cuda_malloc size 
	max_size = SIZE[SIZE.size()-1];
	float *A = nullptr, *C = nullptr,*C_ref = nullptr; // host matrices
	float *dA = nullptr, *dC = nullptr,*dC_ref = nullptr; // device matrices
	fp8_e4m3 *B = nullptr, *dB = nullptr;
	A = (float *)malloc(sizeof(float) * max_size * max_size);
	B = (fp8_e4m3 *)malloc(sizeof(fp8_e4m3) * max_size * max_size);
	C = (float *)malloc(sizeof(float) * max_size * max_size);
	C_ref = (float *)malloc(sizeof(float) * max_size * max_size);
	randomize_matrix<float>(A, max_size * max_size);
	zero_matrix<fp8_e4m3>(B, max_size * max_size);
	zero_matrix<float>(C, max_size * max_size);

	CHECK_CUDA_ERROR(cudaMalloc(&dA, sizeof(float) * max_size * max_size));
	CHECK_CUDA_ERROR(cudaMalloc((void **)&dB, sizeof(fp8_e4m3) * max_size * max_size));
	CHECK_CUDA_ERROR(cudaMalloc((void **)&dC, sizeof(float) * max_size * max_size));//TODO, modify the index here
	CHECK_CUDA_ERROR(cudaMalloc((void **)&dC_ref, sizeof(float) * max_size * max_size));
	//CHECK_CUDA_ERROR(cudaMemcpy(dA, A, sizeof(float) * max_size * max_size,cudaMemcpyHostToDevice));
	//CHECK_CUDA_ERROR(cudaMemcpy(dB, B, sizeof(half) * max_size * max_size,cudaMemcpyHostToDevice));
	//CHECK_CUDA_ERROR(cudaMemcpy(dC, C, sizeof(float) * max_size * max_size,cudaMemcpyHostToDevice));
	//CHECK_CUDA_ERROR(cudaMemcpy(dC_ref, C, sizeof(float) * max_size * max_size,cudaMemcpyHostToDevice));
	int constexpr  BLOCK_SIZE_X = 128;
	int constexpr BLOCK_SIZE_Y = 32;
	int constexpr NUM_PER_THREAD = 8;
	int constexpr NUM_THREADS_PER_BLOCK = BLOCK_SIZE_X * BLOCK_SIZE_Y / NUM_PER_THREAD;
	//int const DATA_TYPE = 1; // 0 is for fp8, 1 is for fp4, 2 is for nfp4
	
	dim3 blockD(NUM_THREADS_PER_BLOCK); // X is for row-major
	for (int size: SIZE){
		//iterate all related size for quantization
		m=n=k=size;
		dim3 grid((n-1)/BLOCK_SIZE_X + 1, (m-1)/BLOCK_SIZE_Y + 1);
		std::cout << "m is " << m << " n is " << n << " and BLOCK_SIZE is " << BLOCK_SIZE_X << std::endl;
		std::cout << "first element is " << A[0] << std::endl;
		CHECK_CUDA_ERROR(cudaMemcpy(dA, A, sizeof(float) * max_size * max_size,cudaMemcpyHostToDevice));
		CHECK_CUDA_ERROR(cudaMemcpy(dB, B, sizeof(fp8_e4m3) * max_size * max_size,cudaMemcpyHostToDevice));
		CHECK_CUDA_ERROR(cudaMemcpy(dC, C, sizeof(float) * max_size * max_size,cudaMemcpyHostToDevice));
		CHECK_CUDA_ERROR(cudaMemcpy(dC_ref, C, sizeof(float) * max_size * max_size,cudaMemcpyHostToDevice));
		//DataType_t const data_type = FP4;
		DataType_t const data_type = General8bit;
		cudaEvent_t start, stop;
		cudaEventCreate(&start);
		cudaEventCreate(&stop);
		cudaEventRecord(start);
		quantize_block_wize<fp8_e4m3, BLOCK_SIZE_X, BLOCK_SIZE_Y, NUM_PER_THREAD, data_type><<<grid, blockD>>>(dA, dB, dC, m, n);
		cudaEventRecord(stop);
		CHECK_CUDA_ERROR(cudaMemcpy(B, dB, sizeof(fp8_e4m3) * max_size * max_size, cudaMemcpyDeviceToHost));
		CHECK_CUDA_ERROR(cudaMemcpy(C, dC, sizeof(float) * max_size * max_size, cudaMemcpyDeviceToHost));
		printf("input A[0] is %f and output B[0] is %f \n ", A[0], (float)B[0]);
		std::cout << "B[0] is " << " C[0] is " << C[0] << std::endl;
		CHECK_CUDA_ERROR(cudaEventSynchronize(stop));
		float milliseconds = 0;
		cudaEventElapsedTime(&milliseconds, start, stop);
		std::cout << "current Elapsed time is: "<<milliseconds << std::endl;
		std::cout << "Effective Bandwidth (GB/s): "<< size*size*5/milliseconds/1e6 << std::endl;

	        	
	}
	return 1;
}
